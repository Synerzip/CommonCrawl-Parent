==================To Do : Add screenshots


Suse linux server 11 SP3 for the experiment

1. Download scripts folder to <PROJECT_HOME>
2. cd <PROJECT_HOME>
3. Launch 3 node on demand medium instances by executing command 
 ./prepare-hdp.sh -v 1.1.0 -k synerzip-bigdata -i /home/synerzip/work/aws/synerzip-bigdata.pem -a ami-88c841e0 -t m3.medium -u ec2-user --ebs-vol-size 8 launch bigdataexpt
4. Copy all the private ip's , these will be used at later stages
5. Login to the ambari server 
	ssh -i <PEM file path> ec2-user@<public dns>
6. Switch to root account by command 
	sudo -i
7. Configure ambari by command
	ambari-server setup
	Note: Keep all default settings i.e. just press enter for every option
8. Start ambari server
	ambari-server start
9. On Chrome/Firefox Browse : http://<public dns>:8080 to get a login page
10. Use credentials admin/admin
11. Enter cluster name e.g bigdatademo
12. Use hostnames copied in step 4
13. Use all default settings, and use next button, select bare minimum services (hdfs, mapreduce,yarn, zookeeper & Tez)
14. Very likely you will get a warning of ntp service not started, to troubleshoot login to each machine 
	ssh -i <PEM file path> ec2-user@<public dns>
	sudo -i
	/etc/init.d/ntp start
15. Deploy cluster
16. ssh to ambari server machine
	ssh -i <PEM file path> ec2-user@<public dns>
	sudo -i
	su - hdfs
17. Download spark binary i.e. tar file [pre-compiled for hadoop 2.4] 
    wget http://d3kbcqa49mib13.cloudfront.net/spark-1.1.0-bin-hadoop2.4.tgz
18. Configure environment variables
	export JAVA_HOME=/usr/jdk64/jdk1.7.0_45
	export YARN_CONF_DIR=/usr/lib/hadoop/etc/hadoop

19.  Test if spark is configured correctly
	./bin/spark-submit --class org.apache.spark.examples.SparkPi    --master yarn-cluster  --num-executors 3 --driver-memory 512m  --executor-memory 512m   --executor-cores 1  lib/spark-examples*.jar 10
20. Test if spark can read file on hdfs 
	./bin/spark-submit --class org.apache.spark.examples.JavaWordCount --master yarn-cluster  --num-executors 3 --driver-memory 512m  --executor-memory 512m   --executor-cores 1  lib/spark-examples*.jar /tmp/wordcount 10




