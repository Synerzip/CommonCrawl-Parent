CommonCrawl-Parent
===============================

CommonCrawl Project has Big Data Programs which run on top of the Common Crawl Dataset (available on AWS S3) to extract certain analytics out of the 500TB Dataset. Apart from extracting the analytics (e.g Usage of Google Ads) from the Dataset, CommonCrawl Synerzip Project also plans to compare Big Data Technologies (e.g MapReduce vs Apache Spark) performances benchmark when extracting such analytics.

CommonCrawl Metrics
-----
TBD

CommonCrawl-Projects
-----
Following are the Common Crawl Projects which are used for extracting analytics and benchmarking Big Data Technologies
* CommonCrawl-MapReduce - Contains various Big Data Analytics for CommonCrawl Dataset based on Apache Hadoop's Map Reduce
* CommonCrawl-Spark - Contains various Big Data Analytics for CommonCrawl Dataset based on Apache Spark, the newer Big Data Ecosystem
* CommonCrawl-Common - Contains the common code.

CommonCrawl Hadoop Cluster Setup
--------
This is the Big Data Experiment we are doing in Synerzip around Common Crawl Database

Setup :

6 xlarge ec2 nodes

Software:

Apache Spark v1.1.0
HDP 2.4 (Hortonworks Distribution)
Ambari 1.6


How to setup and execute CommonCrawl Project?
-----
TBD

